{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing with AI library flake analysis\n",
    "* I tried to train and test flake analysis with the RHV dataset. I couldn't make sense of the results so I tried to deconstruct the code (remove engineering parts). In this notebook, I try to understand how flake analysis model is trained and understand the obtained results.\n",
    "* I bring all the code from extract.py, cluster.py, and ncd.py which makes this notebook bulky, but it's important in terms of debugging the code efficiently\n",
    "* I don't bring in data.py because it is just engineering around data formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# currentdir = os.path.dirname(\n",
    "#                os.path.abspath(\n",
    "#                 inspect.getfile(inspect.currentframe())\n",
    "#                 )\n",
    "#                )\n",
    "# parentdir = os.path.dirname(currentdir)\n",
    "# sys.path.append(parentdir + \"/storage\")\n",
    "# sys.path.append(currentdir + \"/bots\")\n",
    "import boto3\n",
    "import json\n",
    "import tempfile\n",
    "import gzip, pickle\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import uuid\n",
    "import argparse\n",
    "import subprocess\n",
    "import zipfile\n",
    "import json\n",
    "import re\n",
    "import operator\n",
    "import random\n",
    "import tempfile\n",
    "import sklearn.cluster\n",
    "import sklearn.neighbors\n",
    "import numpy\n",
    "import zlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extractor.py\n",
    "* This module is supposed to extract features from the text log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 3\n",
    "# This code extracts features from log items. In particular it normalizes\n",
    "# and exracts the log.\n",
    "#\n",
    "# TODO: We could weight log lines using TF-IDF, but that would require\n",
    "# a distance function that could apply that weight between lines. The\n",
    "# NCD distance we use cannot do that.\n",
    "\n",
    "import calendar\n",
    "import re\n",
    "import time\n",
    "\n",
    "import sklearn.feature_extraction.text\n",
    "\n",
    "# Ignore lines that appear in at least this fraction of logs\n",
    "IGNORE_THRESHHOLD = 0.6\n",
    "\n",
    "# Choose only one out of every N tracked items. These have\n",
    "# already been manually \"clustered\" elsewhere, and we only need\n",
    "# some cluster seeds\n",
    "TRACKER_SPARSE = 100\n",
    "\n",
    "# TODO: We should be able to detect these automatically and ignore them\n",
    "# But for now this is a pragmatic hack to reduce noise and processing time\n",
    "NOISE = {\n",
    "    \"Wrote file\": re.compile(\"Wrote.*\\.(png|html|log)\"),\n",
    "    \"Journal extracted\": re.compile(\"Journal extracted to.*\\.log\"),\n",
    "    \"Core dumps downloaded\": re.compile(\"Core dumps downloaded to.*\\.core\"),\n",
    "    \"not ok\": re.compile(\"^not ok.*\"),\n",
    "    \"ok\": re.compile(\"^ok.*\"),\n",
    "    \"# Flake\": re.compile(\"# Flake.*\"),\n",
    "    'File \"\\\\1\"': re.compile('File \"/[^\"]+/([^/]+)\"'),\n",
    "    \"### \": re.compile('#{3,80}\\s+'),\n",
    "}\n",
    "\n",
    "DIGITS = re.compile('\\d+')\n",
    "\n",
    "# Various features extracted\n",
    "FEATURE_LOG = 0                # string: The normalized and collapsed log extracted\n",
    "FEATURE_INDEX = 1              # number: Unique index of the item\n",
    "FEATURE_URL = 2                # string: The full URL to the test result\n",
    "FEATURE_NAME = 3               # string: The name of the test run\n",
    "FEATURE_CONTEXT = 4            # string: The context in which the test is run\n",
    "FEATURE_TRACKER = 5            # string: A tracker issue for this\n",
    "FEATURE_MERGED = 6             # number: 1 if merged, 0 if not, -1 if unknown\n",
    "FEATURE_TIMESTAMP = 7          # number: The time since epoch at which test was run\n",
    "\n",
    "# Return already tokenized data\n",
    "def noop(value):\n",
    "    return value\n",
    "\n",
    "# Select which items we want to operate on.\n",
    "#\n",
    "# Because we have so many tracked failures, we need to only bring\n",
    "# some of those into our clustering algorithm. We can assume that\n",
    "# these are already clusters\n",
    "tracked = { }\n",
    "def select(item):\n",
    "    if item.get(\"status\") != \"FAILED\":\n",
    "        return False\n",
    "    tracker = item.get(\"tracker\")\n",
    "    if not tracker:\n",
    "        return True\n",
    "    count = tracked[tracker] = tracked.get(tracker, 0) + 1\n",
    "    return count % TRACKER_SPARSE == 0 # Only every Nth for tracked failures\n",
    "\n",
    "# The actual feature extractor. Currently only extracts a\n",
    "# normalized log from each item. By using fit() you can train\n",
    "# the extractor to ignore frequently found lines.\n",
    "class Extractor():\n",
    "    def __init__(self, verbose=False):\n",
    "        self.extract = sklearn.feature_extraction.text.CountVectorizer(\n",
    "            analyzer='word',\n",
    "            tokenizer=noop,\n",
    "            lowercase=False,\n",
    "            max_df=IGNORE_THRESHHOLD)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(item):\n",
    "        result = [ ]\n",
    "        value = item[\"log\"] or \"\"\n",
    "        for line in value.replace('\\r\\n', '\\n').replace('\\r', '\\n').split('\\n'):\n",
    "            line = line.strip()\n",
    "            for substitute, pattern in NOISE.items():\n",
    "                line = pattern.sub(substitute, line)\n",
    "            else:\n",
    "                result.append(DIGITS.sub('000', line))\n",
    "        return result\n",
    "\n",
    "    def fit(self, items, tokenized=None):\n",
    "        tokenized = tokenized or map(Extractor.tokenize, items)\n",
    "        self.extract.fit(tokenized)\n",
    "\n",
    "    def transform(self, items, tokenized=None):\n",
    "        tokenized = list(tokenized or map(Extractor.tokenize, items))\n",
    "        results = [ ]\n",
    "        for index, item in enumerate(items):\n",
    "            if not select(item):\n",
    "                continue\n",
    "            lines = tokenized[index]\n",
    "            filtered = filter(lambda line: line not in self.extract.stop_words_, lines)\n",
    "#             try:\n",
    "#                 timestamp = calendar.timegm(time.strptime(item.get(\"date\", \"\"), \"%Y-%m-%dT%H:%M:%SZ\"))\n",
    "#             except ValueError:\n",
    "            timestamp = -1\n",
    "            merged = item.get(\"merged\")\n",
    "            if merged is None:\n",
    "                merged = -1\n",
    "            else:\n",
    "                merged = merged and 1 or 0\n",
    "            results.append((\n",
    "                \"\\n\".join(filtered),      # FEATURE_LOG\n",
    "                index,                    # FEATURE_INDEX\n",
    "                item.get(\"url\", \"\"),      # FEATURE_URL\n",
    "                item.get(\"test\", \"\"),     # FEATURE_NAME\n",
    "                item.get(\"context\", \"\"),  # FEATURE_CONTEXT\n",
    "                item.get(\"tracker\", \"\"),  # FEATURE_TRACKER\n",
    "                merged,                   # FEATURE_MERGED\n",
    "                timestamp                 # FEATURE_TIMESTAMP\n",
    "            ))\n",
    "        return results\n",
    "\n",
    "    def fit_transform(self, items):\n",
    "        tokenized = list(map(Extractor.tokenize, items))\n",
    "        self.fit(items, tokenized)\n",
    "        return self.transform(items, tokenized)\n",
    "\n",
    "    def stop_tokens(self):\n",
    "        return self.extract.stop_words_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ncd.py\n",
    "* This is the part where the log text is encoded into a compressed version and the distance between them is computed using a normalized compressed distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(val):\n",
    "    result = len(zlib.compress(val.encode('utf-8'), 6))\n",
    "    return float(result)\n",
    "\n",
    "# We use a cache to accelelerate NCD calculations and avoid\n",
    "# same of the re-compression of identical data\n",
    "cache = { }\n",
    "vectors = [ ]\n",
    "\n",
    "def calculate(a, b):\n",
    "    # Zero distance between identical pairs\n",
    "    if a == b:\n",
    "        return 0\n",
    "    # Compression length for individual parts are cached\n",
    "    Ka = cache.get(a)\n",
    "    if Ka is None:\n",
    "        Ka = K(a)\n",
    "    Kb = cache.get(b)\n",
    "    if Kb is None:\n",
    "        Kb = K(b)\n",
    "    # The compression distance for combined\n",
    "    Kab = K(a + b)\n",
    "    return (Kab - min(Ka, Kb)) / max(Ka, Kb)\n",
    "\n",
    "# Precompute all individual hashes to cache and convert to vector array\n",
    "def prepare(values):\n",
    "    values = list(values)\n",
    "    array = numpy.zeros((len(values), 1))\n",
    "    for i, value in enumerate(values):\n",
    "        index = len(vectors)\n",
    "        array[i][0] = index\n",
    "        vectors.append(value)\n",
    "        cache[value] = K(value)\n",
    "    return array\n",
    "\n",
    "# A function usable as a metric in scikit-learn\n",
    "# Make sure to call prepare() first on the actual values\n",
    "def metric(x, y, values=vectors):\n",
    "    i, j = int(x[0]), int(y[0])\n",
    "    return calculate(values[i], values[j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster.py\n",
    "## Relevant parts of class Cluster\n",
    "* The cluster class is basically methods for analyzing the clusters formed by the DBSCAN method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 5\n",
    "FLAKE_THRESHOLD = 0.4\n",
    "\n",
    "# A cluster of items with optional analysis of those items\n",
    "# The items are not stored here, but their points in the\n",
    "# array are.\n",
    "class Cluster():\n",
    "    def __init__(self, label, points):\n",
    "        self.label = label\n",
    "        self.points = points\n",
    "\n",
    "    # Analyse the cluster, based on the points added in\n",
    "    # the cluster. The points should be indexes into the\n",
    "    # items array.\n",
    "    def analyze(self, features):\n",
    "        num_merged = 0\n",
    "\n",
    "        for point in self.points:\n",
    "            merged = features[point][FEATURE_MERGED]\n",
    "            if merged == 1:\n",
    "                num_merged += 1\n",
    "\n",
    "        total = len(self.points)\n",
    "\n",
    "        # Calculate the merged probabilities\n",
    "        if total:\n",
    "            merged = (float(num_merged) / float(total))\n",
    "            if merged > 1:\n",
    "                merged = 1\n",
    "\n",
    "        # Probability that this cluster represents the given name\n",
    "        return {\n",
    "            \"total\": total,\n",
    "            \"merged\": merged,\n",
    "            \"trackers\": self.group_by(features, FEATURE_TRACKER, factor=TRACKER_SPARSE),\n",
    "            \"names\": self.group_by(features, FEATURE_NAME),\n",
    "            \"contexts\": self.group_by(features, FEATURE_CONTEXT)\n",
    "        }\n",
    "\n",
    "    # Figure out how often given values of a feature show up in a cluster\n",
    "    def group_by(self, features, feature, limit=5, factor=1):\n",
    "        values = { }\n",
    "        total = 0\n",
    "        for point in self.points:\n",
    "            value = features[point][feature]\n",
    "            if value:\n",
    "                # If we have a factor, some of the features may be sparse\n",
    "                # So account for the spareness in our probability estimates\n",
    "                values[value] = values.get(value, 0) + factor\n",
    "                total += factor\n",
    "            else:\n",
    "                total += 1\n",
    "        listing = [ ]\n",
    "        for value, count in values.items():\n",
    "            probability = float(count) / float(total or 1)\n",
    "            listing.append((value, min(probability, 1)))\n",
    "        listing.sort(key=operator.itemgetter(1), reverse=True)\n",
    "        return listing[0:limit]\n",
    "\n",
    "    # Dump the selected cluster to disk. The features are the inputs\n",
    "    # from the model that were used to build the cluster.\n",
    "    def dump(self, directory, features, detail=None):\n",
    "        if self.label is None:\n",
    "            label = \"noise\"\n",
    "        else:\n",
    "            label = \"cluster-{0}\".format(self.label)\n",
    "\n",
    "        # Dump our stuff into the directory\n",
    "        if not os.path.exists(directory):\n",
    "            os.mkdir(directory)\n",
    "\n",
    "        path = os.path.join(directory, \"{0}-{1}.log\".format(label, detail or len(self.points)))\n",
    "        with open(path, \"a\") as fp:\n",
    "            for row in self.analyze(features).items():\n",
    "                fp.write(\"{0}: {1}\\n\".format(row[0], repr(row[1])))\n",
    "            fp.write(\"\\n\\n\")\n",
    "            for point in self.points:\n",
    "                url = features[point][extractor.FEATURE_URL]\n",
    "                if url:\n",
    "                    fp.write(\"{0}\\n\".format(url))\n",
    "                fp.write(features[point][extractor.FEATURE_LOG])\n",
    "                fp.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant parts of class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The clustering model. Uses unsupervised clustering to build clusters\n",
    "# out of data extracted from test logs. See extractor.py for the code\n",
    "# that extracts features from the logs.\n",
    "#\n",
    "# Also allows classification into the built clusters.\n",
    "#\n",
    "class Model():\n",
    "    eps = 0.3           # Maximum distance between two samples in neighborhood\n",
    "    min_samples = 3     # Minimum number of samples in a cluster\n",
    "\n",
    "    def __init__(self, verbose=False):\n",
    "        self.clusters = { }      # The actual clustered items\n",
    "        self.verbose = verbose\n",
    "        self.extractor = None\n",
    "        self.features = None\n",
    "\n",
    "    # Perform the unsupervised clustering\n",
    "    def train(self, items):\n",
    "        self.clusters = { }\n",
    "        self.noise = [ ]\n",
    "\n",
    "        items = list(items)\n",
    "\n",
    "        if self.verbose:\n",
    "            sys.stderr.write(\"{0}: Items to train\\n\".format(len(items)))\n",
    "\n",
    "        # Extract the features we want to use for clustering from the items\n",
    "        self.extractor = Extractor()\n",
    "        self.features = self.extractor.fit_transform(items)\n",
    "\n",
    "        jobs = -1\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        # Initialize the NCD code with our log feature. Currently only\n",
    "        # one feature is used: the normalized log\n",
    "        self.X = prepare(map(lambda features: features[FEATURE_LOG], self.features))\n",
    "        \n",
    "        #@s This calls ncd.py which has cache in global scope, check\n",
    "        self.matrix = sklearn.metrics.pairwise.pairwise_distances(self.X, metric=metric, n_jobs=jobs)\n",
    "\n",
    "        if self.verbose:\n",
    "            sys.stderr.write(\"{0}: Computed distances in {1} seconds on {2} cores\\n\".format(\n",
    "                int((len(self.features) * len(self.features)) / 2),\n",
    "                int(time.perf_counter() - start), jobs\n",
    "            ))\n",
    "\n",
    "        # Actually perform the clustering. This is fast compared to above\n",
    "        min_samples = min(self.min_samples, len(self.features) / 10)\n",
    "        dbs = sklearn.cluster.DBSCAN(metric='precomputed', eps=self.eps, min_samples=min_samples)\n",
    "        dbs.fit(self.matrix)\n",
    "        labels = dbs.labels_\n",
    "\n",
    "        # Create clusters of all the items\n",
    "        clusters = { }\n",
    "        noise = [ ]\n",
    "        for i, label in enumerate(labels):\n",
    "            if label == -1:\n",
    "                noise.append(i)\n",
    "            else:\n",
    "                if label not in clusters:\n",
    "                    clusters[label] = [ ]\n",
    "                clusters[label].append(i)\n",
    "        self.clusters = { }\n",
    "        for label, indexes in clusters.items():\n",
    "            self.clusters[label] = Cluster(label, indexes)\n",
    "        self.noise = Cluster(None, noise)\n",
    "\n",
    "        # Print out a rough description of that\n",
    "        if self.verbose:\n",
    "            sys.stderr.write(\"{0}: Clusters ({1} items, {2} noise)\\n\".format(\n",
    "                len(self.clusters.keys()),\n",
    "                len(self.features) - len(noise),\n",
    "                len(noise)\n",
    "            ))\n",
    "\n",
    "        # Setup our neighbors classifier for predict()\n",
    "        self.neighbors = sklearn.neighbors.KNeighborsClassifier(metric='precomputed', weights='distance')\n",
    "        self.neighbors.fit(self.matrix, labels)\n",
    "\n",
    "    # Predict which clusters these items are a part of\n",
    "    # The cluster labels are returned for each item, along with a probability\n",
    "    def predict(self, items):\n",
    "        features = self.extractor.transform(items)\n",
    "        Y = ncd.prepare(map(lambda x: x[0], self.features))\n",
    "        X = ncd.prepare(map(lambda x: x[0], features))\n",
    "        matrix = sklearn.metrics.pairwise.pairwise_distances(X, Y, metric=metric, n_jobs=1)\n",
    "        result = [ ]\n",
    "\n",
    "        # TODO: The probability is currently bogus, we could use distance measurements to fill it in\n",
    "        for label in self.neighbors.predict(matrix):\n",
    "            if label == -1:\n",
    "                result.append((None, 0.0))\n",
    "            else:\n",
    "                # TODO: The problem here is we don't classify noise properly, should use eps (above)\n",
    "                result.append((label, 0.5))\n",
    "        return result\n",
    "\n",
    "    # Dump the cluster's models and noise to a directory\n",
    "    def dump(self, directory):\n",
    "        for label, cluster in self.clusters.items():\n",
    "            cluster.dump(directory, self.features)\n",
    "        self.noise.dump(directory, self.features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a dummy dataset\n",
    "* I design a dataset (same format as a real dataset) with 20 items\n",
    "* Each item has a log message randomly chosen from 3 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\"The test failed because of bad code\", \"This is system error\", \"These are some kernel warinings\"]\n",
    "\n",
    "\n",
    "training_data = []\n",
    "for i in range(20):\n",
    "    item = {\"id\":\"041f6832-aa14-4f6e-891d-31aaf8d7ed01\",\n",
    "        \"status\":\"FAILED\",\n",
    "        \"pull\":7331,\n",
    "        \"log\":random.choice(messages),\n",
    "        \"test\":\"testFormatTypes (check_storage_format.TestStorage)\",\n",
    "        \"context\":\"verify/debian-testing\",\n",
    "        \"date\":-1,\n",
    "        \"merged\":True,\n",
    "        \"revision\":\"b32635869b9e87cdd9e42b6e6123150d500f6862\"}\n",
    "    training_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20: Items to train\n",
      "200: Computed distances in 0 seconds on -1 cores\n",
      "3: Clusters (20 items, 0 noise)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "#import learn.cluster\n",
    "#items = list(learn.data.load(inp, only=learn.data.failures, verbose=True))\n",
    "model = Model(verbose=True)\n",
    "model.train(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the training process\n",
    "* We have 3 clusters trained \n",
    "* Next, we try to understand how we got them\n",
    "* The first part of the train function in the class Model is exctracting features using class Extractor\n",
    "* Printing model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This is system error',\n",
       "  0,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('These are some kernel warinings',\n",
       "  1,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('This is system error',\n",
       "  2,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('The test failed because of bad code',\n",
       "  3,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('This is system error',\n",
       "  4,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('These are some kernel warinings',\n",
       "  5,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('The test failed because of bad code',\n",
       "  6,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('This is system error',\n",
       "  7,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('The test failed because of bad code',\n",
       "  8,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('These are some kernel warinings',\n",
       "  9,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('The test failed because of bad code',\n",
       "  10,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('The test failed because of bad code',\n",
       "  11,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('The test failed because of bad code',\n",
       "  12,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('The test failed because of bad code',\n",
       "  13,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('These are some kernel warinings',\n",
       "  14,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('This is system error',\n",
       "  15,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('The test failed because of bad code',\n",
       "  16,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('The test failed because of bad code',\n",
       "  17,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('This is system error',\n",
       "  18,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1),\n",
       " ('This is system error',\n",
       "  19,\n",
       "  '',\n",
       "  'testFormatTypes (check_storage_format.TestStorage)',\n",
       "  'verify/debian-testing',\n",
       "  '',\n",
       "  1,\n",
       "  -1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The result is not a matrix of numbers as would be expected in count vectorizer\n",
    "* Count vectorizer is trained (fit) but never used as a transformer (see class Extractor in this notebook)\n",
    "* I don't really understand the point of extractor.py, is it just to select \"FAILED\" cases ans remove stop words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving ahead\n",
    "* The next steps in the train function is to use code from ncd.py \n",
    "* The prepare and metric function\n",
    "* This returns self.X and self.matrix which is used for training DBSCAN\n",
    "* Printing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [12.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [15.],\n",
       "       [16.],\n",
       "       [17.],\n",
       "       [18.],\n",
       "       [19.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.74358974, 0.        , 0.74418605, 0.        ,\n",
       "        0.74358974, 0.74418605, 0.        , 0.74418605, 0.74358974,\n",
       "        0.74418605, 0.74418605, 0.74418605, 0.74418605, 0.74358974,\n",
       "        0.        , 0.74418605, 0.74418605, 0.        , 0.        ],\n",
       "       [0.74358974, 0.        , 0.74358974, 0.60465116, 0.74358974,\n",
       "        0.        , 0.60465116, 0.74358974, 0.60465116, 0.        ,\n",
       "        0.60465116, 0.60465116, 0.60465116, 0.60465116, 0.        ,\n",
       "        0.74358974, 0.60465116, 0.60465116, 0.74358974, 0.74358974],\n",
       "       [0.        , 0.74358974, 0.        , 0.74418605, 0.        ,\n",
       "        0.74358974, 0.74418605, 0.        , 0.74418605, 0.74358974,\n",
       "        0.74418605, 0.74418605, 0.74418605, 0.74418605, 0.74358974,\n",
       "        0.        , 0.74418605, 0.74418605, 0.        , 0.        ],\n",
       "       [0.74418605, 0.60465116, 0.74418605, 0.        , 0.74418605,\n",
       "        0.60465116, 0.        , 0.74418605, 0.        , 0.60465116,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60465116,\n",
       "        0.74418605, 0.        , 0.        , 0.74418605, 0.74418605],\n",
       "       [0.        , 0.74358974, 0.        , 0.74418605, 0.        ,\n",
       "        0.74358974, 0.74418605, 0.        , 0.74418605, 0.74358974,\n",
       "        0.74418605, 0.74418605, 0.74418605, 0.74418605, 0.74358974,\n",
       "        0.        , 0.74418605, 0.74418605, 0.        , 0.        ],\n",
       "       [0.74358974, 0.        , 0.74358974, 0.60465116, 0.74358974,\n",
       "        0.        , 0.60465116, 0.74358974, 0.60465116, 0.        ,\n",
       "        0.60465116, 0.60465116, 0.60465116, 0.60465116, 0.        ,\n",
       "        0.74358974, 0.60465116, 0.60465116, 0.74358974, 0.74358974],\n",
       "       [0.74418605, 0.60465116, 0.74418605, 0.        , 0.74418605,\n",
       "        0.60465116, 0.        , 0.74418605, 0.        , 0.60465116,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60465116,\n",
       "        0.74418605, 0.        , 0.        , 0.74418605, 0.74418605],\n",
       "       [0.        , 0.74358974, 0.        , 0.74418605, 0.        ,\n",
       "        0.74358974, 0.74418605, 0.        , 0.74418605, 0.74358974,\n",
       "        0.74418605, 0.74418605, 0.74418605, 0.74418605, 0.74358974,\n",
       "        0.        , 0.74418605, 0.74418605, 0.        , 0.        ],\n",
       "       [0.74418605, 0.60465116, 0.74418605, 0.        , 0.74418605,\n",
       "        0.60465116, 0.        , 0.74418605, 0.        , 0.60465116,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60465116,\n",
       "        0.74418605, 0.        , 0.        , 0.74418605, 0.74418605],\n",
       "       [0.74358974, 0.        , 0.74358974, 0.60465116, 0.74358974,\n",
       "        0.        , 0.60465116, 0.74358974, 0.60465116, 0.        ,\n",
       "        0.60465116, 0.60465116, 0.60465116, 0.60465116, 0.        ,\n",
       "        0.74358974, 0.60465116, 0.60465116, 0.74358974, 0.74358974],\n",
       "       [0.74418605, 0.60465116, 0.74418605, 0.        , 0.74418605,\n",
       "        0.60465116, 0.        , 0.74418605, 0.        , 0.60465116,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60465116,\n",
       "        0.74418605, 0.        , 0.        , 0.74418605, 0.74418605],\n",
       "       [0.74418605, 0.60465116, 0.74418605, 0.        , 0.74418605,\n",
       "        0.60465116, 0.        , 0.74418605, 0.        , 0.60465116,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60465116,\n",
       "        0.74418605, 0.        , 0.        , 0.74418605, 0.74418605],\n",
       "       [0.74418605, 0.60465116, 0.74418605, 0.        , 0.74418605,\n",
       "        0.60465116, 0.        , 0.74418605, 0.        , 0.60465116,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60465116,\n",
       "        0.74418605, 0.        , 0.        , 0.74418605, 0.74418605],\n",
       "       [0.74418605, 0.60465116, 0.74418605, 0.        , 0.74418605,\n",
       "        0.60465116, 0.        , 0.74418605, 0.        , 0.60465116,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60465116,\n",
       "        0.74418605, 0.        , 0.        , 0.74418605, 0.74418605],\n",
       "       [0.74358974, 0.        , 0.74358974, 0.60465116, 0.74358974,\n",
       "        0.        , 0.60465116, 0.74358974, 0.60465116, 0.        ,\n",
       "        0.60465116, 0.60465116, 0.60465116, 0.60465116, 0.        ,\n",
       "        0.74358974, 0.60465116, 0.60465116, 0.74358974, 0.74358974],\n",
       "       [0.        , 0.74358974, 0.        , 0.74418605, 0.        ,\n",
       "        0.74358974, 0.74418605, 0.        , 0.74418605, 0.74358974,\n",
       "        0.74418605, 0.74418605, 0.74418605, 0.74418605, 0.74358974,\n",
       "        0.        , 0.74418605, 0.74418605, 0.        , 0.        ],\n",
       "       [0.74418605, 0.60465116, 0.74418605, 0.        , 0.74418605,\n",
       "        0.60465116, 0.        , 0.74418605, 0.        , 0.60465116,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60465116,\n",
       "        0.74418605, 0.        , 0.        , 0.74418605, 0.74418605],\n",
       "       [0.74418605, 0.60465116, 0.74418605, 0.        , 0.74418605,\n",
       "        0.60465116, 0.        , 0.74418605, 0.        , 0.60465116,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60465116,\n",
       "        0.74418605, 0.        , 0.        , 0.74418605, 0.74418605],\n",
       "       [0.        , 0.74358974, 0.        , 0.74418605, 0.        ,\n",
       "        0.74358974, 0.74418605, 0.        , 0.74418605, 0.74358974,\n",
       "        0.74418605, 0.74418605, 0.74418605, 0.74418605, 0.74358974,\n",
       "        0.        , 0.74418605, 0.74418605, 0.        , 0.        ],\n",
       "       [0.        , 0.74358974, 0.        , 0.74418605, 0.        ,\n",
       "        0.74358974, 0.74418605, 0.        , 0.74418605, 0.74358974,\n",
       "        0.74418605, 0.74418605, 0.74418605, 0.74418605, 0.74358974,\n",
       "        0.        , 0.74418605, 0.74418605, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding prepare and other operations in ncd.py\n",
    "* self.X is not feature matrix for the model or count vectorizer matrix like I thought, it is a cached set in ncd.py. Values of self.X corresponds to keys of cache in ncd.py\n",
    "* The values in cache in ncd.py is the length of compressed string (see function ncd.K in this notebook)\n",
    "* Now, the normalized difference in the compressed values are used as distance for clustering \n",
    "* Printing cache and calculation of k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This is system error': 26.0,\n",
       " 'These are some kernel warinings': 39.0,\n",
       " 'The test failed because of bad code': 43.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is system error',\n",
       " 'These are some kernel warinings',\n",
       " 'This is system error',\n",
       " 'The test failed because of bad code',\n",
       " 'This is system error',\n",
       " 'These are some kernel warinings',\n",
       " 'The test failed because of bad code',\n",
       " 'This is system error',\n",
       " 'The test failed because of bad code',\n",
       " 'These are some kernel warinings',\n",
       " 'The test failed because of bad code',\n",
       " 'The test failed because of bad code',\n",
       " 'The test failed because of bad code',\n",
       " 'The test failed because of bad code',\n",
       " 'These are some kernel warinings',\n",
       " 'This is system error',\n",
       " 'The test failed because of bad code',\n",
       " 'The test failed because of bad code',\n",
       " 'This is system error',\n",
       " 'This is system error']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7435897435897436"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate(vectors[0], vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model results\n",
    "\n",
    "* It seems to work for this simple example \n",
    "* We get three clusters with same messages clustered together\n",
    "* But it sould not translate to bigger datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This is system error', 1.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.clusters[0].group_by(model.features, FEATURE_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 7, 15, 18, 19]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.clusters[0].points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('These are some kernel warinings', 1.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.clusters[1].group_by(model.features, FEATURE_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 9, 14]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.clusters[1].points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The test failed because of bad code', 1.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.clusters[2].group_by(model.features, FEATURE_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 8, 10, 11, 12, 13, 16, 17]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.clusters[2].points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with RHV dataset (WIP)\n",
    "* This may require this file to be in ai-library/flakeanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET PARAMETERS TO ACCESS S3 BACKEND\n",
    "s3Path = 'ccit'\n",
    "s3Destination = 'ccit/model1.model'\n",
    "s3endpointUrl = 'https://s3.upshift.redhat.com/'\n",
    "s3objectStoreLocation = 'DH-PLAYPEN'\n",
    "s3accessKey = \"key\"\n",
    "s3secretKey = 'key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE CONNECTION TO S3 BACKEND\n",
    "session = boto3.Session(aws_access_key_id=s3accessKey,\n",
    "                        aws_secret_access_key=s3secretKey)\n",
    "s3 = session.resource('s3', endpoint_url=s3endpointUrl, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD TRAINING DATA\n",
    "objects = []\n",
    "bucket = s3.Bucket(name=s3objectStoreLocation)\n",
    "FilesNotFound = True\n",
    "for obj in bucket.objects.filter(Prefix=s3Path):\n",
    "   objects.append(obj.key)\n",
    "\n",
    "# get list of all availble objects\n",
    "for obj in bucket.objects.filter(Prefix=s3Path):\n",
    "    objects.append(obj.key)\n",
    "    \n",
    "count_both = 0\n",
    "training_data = []\n",
    "for key in objects:\n",
    "    obj = s3.Object(s3objectStoreLocation, key)\n",
    "    contents = obj.get()['Body'].read().decode('utf-8')\n",
    "    if contents:\n",
    "        jcontents = json.loads(contents)\n",
    "        if jcontents[\"log\"] != \"[]\" and jcontents[\"status\"] == \"FAILED\":\n",
    "            training_data.append(jcontents)\n",
    "            count_both += 1\n",
    "            print(count_both)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save useful data on shanand/ccit\n",
    "for e,tdata in enumerate(training_data):\n",
    "    obj = s3.Object(s3objectStoreLocation, f'shanand/ccit/training/{e}.json')\n",
    "    obj.put(Body=json.dumps(tdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load required data from shanand/ccit\n",
    "number_training_samples = 100\n",
    "training_data = []\n",
    "for i in range(number_training_samples):\n",
    "    obj = s3.Object(s3objectStoreLocation, f'shanand/ccit/training/{i}.json')\n",
    "    content = obj.get()['Body'].read().decode('utf-8')\n",
    "    if content:\n",
    "        cdict = json.loads(content)\n",
    "        training_data.append(cdict)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_merged = 0\n",
    "for record in training_data:\n",
    "    if record['merged']:\n",
    "        count_merged += 1\n",
    "count_merged    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN MODEL\n",
    "#import learn.cluster\n",
    "#items = list(learn.data.load(inp, only=learn.data.failures, verbose=True))\n",
    "model = Model(verbose=True)\n",
    "model.train(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with gzip.open('/tmp/tmpun1jn2op/bots/images/tests-learn-5-3.model', 'rb') as fp:\n",
    "    model = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy example test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.5), (2, 0.5)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = {\"id\":\"041f6832-aa14-4f6e-891d-31aaf8d7ed01\",\n",
    "        \"status\":\"FAILED\",\n",
    "        \"pull\":7331,\n",
    "        \"log\":\"SOME_MESSAGE\",\n",
    "        \"test\":\"testFormatTypes (check_storage_format.TestStorage)\",\n",
    "        \"context\":\"verify/debian-testing\",\n",
    "        \"date\":-1,\n",
    "        \"merged\":True,\n",
    "        \"revision\":\"b32635869b9e87cdd9e42b6e6123150d500f6862\"}\n",
    "result = model.predict([item, item])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train dataset example test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10: Items loaded\n"
     ]
    }
   ],
   "source": [
    "inp = open(\"/tmp/tmpr63oj8fw/bots/images/data.jsonl\", 'r')\n",
    "items = list(learn.data.load(inp, only=learn.data.failures, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 0.0),\n",
       " (None, 0.0),\n",
       " (None, 0.0),\n",
       " (None, 0.0),\n",
       " (None, 0.0),\n",
       " (None, 0.0),\n",
       " (None, 0.0),\n",
       " (None, 0.0),\n",
       " (None, 0.0),\n",
       " (None, 0.0)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
